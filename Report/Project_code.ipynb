{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries for the data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "print('libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset\n",
    "website_url='https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv'\n",
    "df= pd.read_csv(website_url)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Exploratory data analysis\n",
    "# count the incidents in each year\n",
    "df_1=df[['SEVERITYCODE','COLLISIONTYPE','JUNCTIONTYPE','ADDRTYPE','OBJECTID','PERSONCOUNT','PEDCOUNT','PEDCYLCOUNT','VEHCOUNT']]\n",
    "df_1=df.dropna()\n",
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_type=df_1['OBJECTID'].groupby([df_1['SEVERITYCODE'],df_1['COLLISIONTYPE']]).agg({'count'})\n",
    "incidents_type=incidents_type.reset_index()\n",
    "incidents_type\n",
    "f1=incidents_type[incidents_type.SEVERITYCODE==1]\n",
    "f2=incidents_type[incidents_type.SEVERITYCODE==2]\n",
    "\n",
    "labels=f1['COLLISIONTYPE']\n",
    "s1=f1['count']\n",
    "s2=f2['count']\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "ax.barh(x, s1, width, color='orange', label='Code 1')\n",
    "ax.barh(x + width, s2, width, color='green', label='Code 2')\n",
    "\n",
    "ax.set(yticks=x + width, yticklabels=labels, ylim=[2*width - 1, len(labels)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_type=df['OBJECTID'].groupby([df['SEVERITYCODE'],df['WEATHER']]).agg({'count'})\n",
    "weather_type=weather_type.reset_index()\n",
    "weather_type\n",
    "w1=weather_type[weather_type.SEVERITYCODE==1]\n",
    "w2=weather_type[weather_type.SEVERITYCODE==2]\n",
    "\n",
    "w1\n",
    "w2\n",
    "\n",
    "labels=w1['WEATHER']\n",
    "q1=w1['count']\n",
    "q2=w2['count']\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "ax.barh(x, q1, width, color='purple', label='Code 1')\n",
    "ax.barh(x + width, q2, width, color='blue', label='Code 2')\n",
    "\n",
    "ax.set(yticks=x + width, yticklabels=labels, ylim=[2*width - 1, len(labels)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junction_type=df['OBJECTID'].groupby([df['SEVERITYCODE'],df['JUNCTIONTYPE']]).agg({'count'})\n",
    "junction_type=junction_type.reset_index()\n",
    "junction_type\n",
    "j1=junction_type[junction_type.SEVERITYCODE==1]\n",
    "j2=junction_type[junction_type.SEVERITYCODE==2]\n",
    "\n",
    "j1\n",
    "j2\n",
    "\n",
    "label3=j1['JUNCTIONTYPE']\n",
    "jf1=j1['count']\n",
    "jf2=j2['count']\n",
    "\n",
    "x = np.arange(len(label3))  # the label locations\n",
    "width = 0.4  # the width of the bars\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "ax.barh(x, jf1, width, color='blueviolet', label='Code 1')\n",
    "ax.barh(x + width, jf2, width, color='burlywood', label='Code 2')\n",
    "\n",
    "ax.set(yticks=x + width, yticklabels=label3, ylim=[2*width - 1, len(label3)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROADCOND=df['OBJECTID'].groupby([df['SEVERITYCODE'],df['ROADCOND']]).agg({'count'})\n",
    "ROADCOND=ROADCOND.reset_index()\n",
    "ROADCOND\n",
    "r1=ROADCOND[ROADCOND.SEVERITYCODE==1]\n",
    "r2=ROADCOND[ROADCOND.SEVERITYCODE==2]\n",
    "\n",
    "r1\n",
    "r2\n",
    "label4=r1['ROADCOND']\n",
    "rf1=r1['count']\n",
    "rf2=r2['count']\n",
    "\n",
    "x = np.arange(len(label4))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "ax.barh(x, rf1, width, color='cornflowerblue', label='Code 1')\n",
    "ax.barh(x + width, rf2, width, color='crimson', label='Code 2')\n",
    "\n",
    "ax.set(yticks=x + width, yticklabels=label4, ylim=[2*width - 1, len(label3)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIGHTCOND=df['OBJECTID'].groupby([df['SEVERITYCODE'],df['LIGHTCOND']]).agg({'count'})\n",
    "LIGHTCOND=LIGHTCOND.reset_index()\n",
    "LIGHTCOND\n",
    "l1=LIGHTCOND[LIGHTCOND.SEVERITYCODE==1]\n",
    "l2=LIGHTCOND[LIGHTCOND.SEVERITYCODE==2]\n",
    "\n",
    "l1\n",
    "l2\n",
    "label5=l1['LIGHTCOND']\n",
    "lf1=l1['count']\n",
    "lf2=l2['count']\n",
    "\n",
    "x = np.arange(len(label5))  # the label locations\n",
    "width = 0.4  # the width of the bars\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "ax.barh(x, lf1, width, color='darkorange', label='Code 1')\n",
    "ax.barh(x + width, lf2, width, color='darkslateblue', label='Code 2')\n",
    "\n",
    "ax.set(yticks=x + width, yticklabels=label5, ylim=[2*width - 1, len(label3)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Check the null or NaN in the dataset\n",
    "missing_data=df.isnull()\n",
    "missing_data.head()\n",
    "\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print(missing_data[column].value_counts())\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all irrelevant variables in the dataset\n",
    "df = df.drop(['OBJECTID','INCKEY','LOCATION','COLDETKEY','REPORTNO','STATUS','INTKEY','EXCEPTRSNCODE','EXCEPTRSNDESC','SEVERITYDESC','INCDATE','SDOT_COLCODE','SDOT_COLDESC','SDOTCOLNUM','ST_COLCODE','ST_COLDESC','SEGLANEKEY','CROSSWALKKEY','INCDTTM'],axis=1)\n",
    "df=df.drop('SEVERITYCODE.1',axis=1)\n",
    "df.rename(columns={'X':'Longitude','Y':'Latitude'},inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the columns with too much missing values\n",
    "df = df.drop([\"INATTENTIONIND\",\"PEDROWNOTGRNT\",\"SPEEDING\"],axis=1)\n",
    "\n",
    "#handle the typo and unclear value with NaN and drop it\n",
    "df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df.replace(\"Unknown\", np.nan, inplace = True)\n",
    "df.replace(\"Other\", np.nan, inplace = True)\n",
    "\n",
    "#drop the missing values in the rest columns\n",
    "df.dropna(subset=[\"Longitude\",\"Latitude\",\"COLLISIONTYPE\",\"JUNCTIONTYPE\",\"UNDERINFL\",\"WEATHER\",\"ROADCOND\",\"LIGHTCOND\"], axis=0, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEVERITYCODE'].value_counts()\n",
    "\n",
    "#creating a balanced dataset\n",
    "df= df.sample(frac=1,random_state=0,replace=False)\n",
    "\n",
    "#separate code 2  from original dataset.\n",
    "df_code2 = df.loc[df['SEVERITYCODE'] == 2]\n",
    "\n",
    "#select 58188 observations from the severity code 1(it has more values than code 2)\n",
    "df_code1 = df.loc[df['SEVERITYCODE'] == 1].sample(n=48926,random_state=42)\n",
    "\n",
    "#get balanced dataset\n",
    "df_balanced = pd.concat([df_code1,df_code2])\n",
    "df_balanced = df_balanced.sample(frac=1,random_state=0,replace=False)\n",
    "\n",
    "#Replacing 0 with N and 1 with Y as this column has mixed datatype values, making it consistent\n",
    "df_balanced['UNDERINFL'] = df_balanced['UNDERINFL'].replace(['0'],'N')\n",
    "df_balanced['UNDERINFL'] = df_balanced['UNDERINFL'].replace(['1'],'Y')\n",
    "\n",
    "#checking if dataset balanced\n",
    "df_balanced.info()\n",
    "df_balanced['SEVERITYCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = df_balanced.iloc[:,1:]\n",
    "#Encoding Categorical Features - Training Dataset\n",
    "A = pd.get_dummies(data=A, columns=['ADDRTYPE','COLLISIONTYPE','JUNCTIONTYPE','WEATHER','ROADCOND','LIGHTCOND','UNDERINFL','HITPARKEDCAR'])\n",
    "\n",
    "B = df_balanced[['SEVERITYCODE']]\n",
    "A.info()\n",
    "A_train, A_test, B_train, B_test = train_test_split(A,B,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling training data as per the requirements\n",
    "scaler = StandardScaler()\n",
    "A_train[['Longitude','Latitude','PERSONCOUNT','PEDCOUNT','PEDCYLCOUNT','VEHCOUNT']] = scaler.fit_transform(A_train[['Longitude','Latitude','PERSONCOUNT','PEDCOUNT','PEDCYLCOUNT','VEHCOUNT']])\n",
    "\n",
    "#Scaling test data as per the requirements\n",
    "scaler = StandardScaler()\n",
    "A_test[['Longitude','Latitude','PERSONCOUNT','PEDCOUNT','PEDCYLCOUNT','VEHCOUNT']] = scaler.fit_transform(A_test[['Longitude','Latitude','PERSONCOUNT','PEDCOUNT','PEDCYLCOUNT','VEHCOUNT']])\n",
    "\n",
    "A_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.concat([B_train,A_train])\n",
    "df_corr = df_corr.corr()\n",
    "df_corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "seaborn.heatmap(df_corr,annot=True,cmap='coolwarm')\n",
    "plt.savefig('correlation.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Machine Learning Algorithm\n",
    "## LogisticRegression FOR THE FOLLOWING ANALYSIS\n",
    "#Fitting and Predictions\n",
    "lr = LogisticRegression(random_state = 0)\n",
    "lr.fit(A_train,B_train)\n",
    "lr_predictions = lr.predict(A_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "lr_cm = confusion_matrix(B_test,lr_predictions)\n",
    "print(lr_cm,'\\n')\n",
    "\n",
    "#Classification Report\n",
    "lr_cr = classification_report(B_test,lr_predictions)\n",
    "print(lr_cr,'\\n')\n",
    "\n",
    "#Accuracy\n",
    "acc = accuracy_score(B_test,lr_predictions)\n",
    "print(acc,'\\n')\n",
    "accDict = {}\n",
    "accDict['LR'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNeighborsClassifier for the Machine Learning process\n",
    "\n",
    "#Fitting and Predictions\n",
    "knn = KNeighborsClassifier()\n",
    "params = {'n_neighbors':[3,4,5,6,7],'p':[1,2]}\n",
    "knn1 = GridSearchCV(knn, param_grid=params)\n",
    "knn1.fit(A_train,B_train.values.ravel())\n",
    "knn_predictions = knn1.predict(A_test)\n",
    "\n",
    "print('Best Hyperparameter KNN : ',knn1.best_params_)\n",
    "\n",
    "#Confusion Matrix\n",
    "knn_cm = confusion_matrix(B_test,knn_predictions)\n",
    "print(knn_cm,'\\n')\n",
    "\n",
    "#Classification Report\n",
    "knn_cr = classification_report(B_test,knn_predictions)\n",
    "print(knn_cr,'\\n')\n",
    "\n",
    "#Accuracy\n",
    "acc = accuracy_score(B_test,knn_predictions)\n",
    "print(acc,'\\n')\n",
    "accDict['KNN'] = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(A_train,B_train)\n",
    "nb_predictions = nb.predict(A_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "nb_cm=confusion_matrix(B_test,nb_predictions)\n",
    "print(nb_cm,'\\n')\n",
    "\n",
    "#Classification Report\n",
    "nb_cr = classification_report(B_test,nb_predictions)\n",
    "print(nb_cr,'\\n')\n",
    "\n",
    "#Accuracy\n",
    "acc = accuracy_score(B_test,nb_predictions)\n",
    "print(acc,'\\n')\n",
    "accDict['NB'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting and Predictions\n",
    "svc = SVC()\n",
    "params = {'kernel':['linear','rbf'], \n",
    "          'random_state':[0]}\n",
    "svc1 = GridSearchCV(svc, param_grid=params)\n",
    "svc1.fit(A_train,B_train)\n",
    "svc_predictions = svc1.predict(A_test)\n",
    "print('Best Hyperparameter SVM : ',svc1.best_params_)\n",
    "\n",
    "#Confusion Matrix\n",
    "svc_cm=confusion_matrix(B_test,svc_predictions)\n",
    "print(svc_cm,'\\n')\n",
    "\n",
    "#Classification Report\n",
    "svc_cr = classification_report(B_test,svc_predictions)\n",
    "print(svc_cr,'\\n')\n",
    "\n",
    "#Accuracy\n",
    "acc = accuracy_score(B_test,svc_predictions)\n",
    "print(acc,'\\n')\n",
    "accDict['SVC'] = acc"
   ]
  }
 ]
}